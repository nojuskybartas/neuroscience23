{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laden-lender",
   "metadata": {},
   "source": [
    "# Cognitive Neuroscience: Group Project 2022\n",
    "\n",
    "## Final Group Project Code Instructions\n",
    "\n",
    "Marijn van Wingerden, Department of Cognitive Science and Artificial Intelligence â€“ Tilburg University Academic Year 21-22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-stone",
   "metadata": {},
   "source": [
    "## Handing in of your code\n",
    "\n",
    "You can adapt this script template and hand it in for the weekly Group Project Assignments. Whenever you encounter ... in the code, you should complete the code in place (of course you can add lines before and after). \"Your code here\" indicates where code blocks should go.\n",
    "\n",
    "Whenever you are asked to make a plot, it should be completed with a meaningful plot title, xlabel and ylabel texts. Figures are started with a Matplotlib figure handle: \"fig_Q2A, ax = plt.subplots;\". This indicates that a link (called handle) to your figure will be saved in the variable, so we can easily check it when checking your scripts. Whenever a naming convention for a variable is given, use it, because it will allow semi-automatic grading of your project script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-experience",
   "metadata": {},
   "source": [
    "## Group members:\n",
    "\n",
    "Please list the contributors and their U-numbers here in comments:\n",
    "\n",
    "- \n",
    "-\n",
    "- \n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-corporation",
   "metadata": {},
   "source": [
    "## Setting up: list your modules to import\n",
    "For loading/saving puroposes, we will make use of the **os** package.\n",
    "An example worksheet with instructions on how to use the os package will be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "expensive-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fft as fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-beaver",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "In your assignment, you will compare neural data in different trial conditions from the same participant: this is a *within-subject* comparison. You can think of this as a contrast: which spectral features are more present in condition A vs. condition B?\n",
    "\n",
    "The second level of the analysis focuses on group statistics. You will answer a question like: \"As a group, do the participants in group [RM/RB/RL] show more spectral power in the [delta/theta/alpha/beta/gamma] band in the ambiguous sentences vs. the non-ambiguous sentences?\"\n",
    "\n",
    "The analysis will start with setting up data structures (refer to WorkSheet 0) that will hold the relevant data. Because EEG activity can differ between participants (due to e.g. anatomical differences like skull thickness or skin conductivity), the **absolute** voltages that we record are not completely informative. Instead, we will be looking at **relative** differences within an individual to remove the between-subject effects that we cannot control. \n",
    "\n",
    "Each datafile that you have been given has the trials related to a particular condition (NA-IR and AM-IR, for example). \"Control\" refers to the non-ambiguous conditions, and \"Experimental\" to the ambiguous condition. \n",
    "Please note that the SF and OF trial types have been ignored (that is, added together). The datafiles are NumPy arrays that have been saved to disk. These arrays are 3D arrays: \n",
    "- the 0 dimension is the trial repetitions\n",
    "- the 1st dimension is the number of channels\n",
    "- the 2nd dimension if the number of samples in a trial\n",
    "    - for the baseline, this is 0.55s of data (276 samples: from -0.05s to +0.5s)\n",
    "    - for the evoked period, this is 1.5s of data (751 samples: from -0.5s to +1.0s)\n",
    "\n",
    "You will need to load the datafiles from all participants and add them all together so that we end up with a 4D matrix that has nParticipants x nTrials x nChannels x nTime. You can make your work easier by organising the datafiles in such a way that you put the control.npy files in their own subdirectory, and the experimental.npy files as well. \n",
    "\n",
    "In order to load the files, we can use the os package.\n",
    "\n",
    "Adapt the following so that it works on your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "creative-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the path to the base directory where the folder called group_xx is located\n",
    "path_base = os.path.normpath('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "exotic-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group_04_part_01_control.npy',\n",
      " 'group_04_part_02_control.npy',\n",
      " 'group_04_part_03_control.npy',\n",
      " 'group_04_part_04_control.npy',\n",
      " 'group_04_part_05_control.npy',\n",
      " 'group_04_part_06_control.npy',\n",
      " 'group_04_part_07_control.npy',\n",
      " 'group_04_part_08_control.npy',\n",
      " 'group_04_part_09_control.npy',\n",
      " 'group_04_part_10_control.npy',\n",
      " 'group_04_part_11_control.npy',\n",
      " 'group_04_part_12_control.npy',\n",
      " 'group_04_part_13_control.npy',\n",
      " 'group_04_part_14_control.npy',\n",
      " 'group_04_part_15_control.npy']\n",
      "the number of control files is:  15 \n",
      "\n",
      "['group_04_part_01_experimental.npy',\n",
      " 'group_04_part_02_experimental.npy',\n",
      " 'group_04_part_03_experimental.npy',\n",
      " 'group_04_part_04_experimental.npy',\n",
      " 'group_04_part_05_experimental.npy',\n",
      " 'group_04_part_06_experimental.npy',\n",
      " 'group_04_part_07_experimental.npy',\n",
      " 'group_04_part_08_experimental.npy',\n",
      " 'group_04_part_09_experimental.npy',\n",
      " 'group_04_part_10_experimental.npy',\n",
      " 'group_04_part_11_experimental.npy',\n",
      " 'group_04_part_12_experimental.npy',\n",
      " 'group_04_part_13_experimental.npy',\n",
      " 'group_04_part_14_experimental.npy',\n",
      " 'group_04_part_15_experimental.npy']\n",
      "the number of experimental files is:  15 \n",
      "\n",
      "['group_04_part_01_control_baseline.npy',\n",
      " 'group_04_part_02_control_baseline.npy',\n",
      " 'group_04_part_03_control_baseline.npy',\n",
      " 'group_04_part_04_control_baseline.npy',\n",
      " 'group_04_part_05_control_baseline.npy',\n",
      " 'group_04_part_06_control_baseline.npy',\n",
      " 'group_04_part_07_control_baseline.npy',\n",
      " 'group_04_part_08_control_baseline.npy',\n",
      " 'group_04_part_09_control_baseline.npy',\n",
      " 'group_04_part_10_control_baseline.npy',\n",
      " 'group_04_part_11_control_baseline.npy',\n",
      " 'group_04_part_12_control_baseline.npy',\n",
      " 'group_04_part_13_control_baseline.npy',\n",
      " 'group_04_part_14_control_baseline.npy',\n",
      " 'group_04_part_15_control_baseline.npy']\n",
      "the number of baseline control files is:  15 \n",
      "\n",
      "['group_04_part_01_experimental_baseline.npy',\n",
      " 'group_04_part_02_experimental_baseline.npy',\n",
      " 'group_04_part_03_experimental_baseline.npy',\n",
      " 'group_04_part_04_experimental_baseline.npy',\n",
      " 'group_04_part_05_experimental_baseline.npy',\n",
      " 'group_04_part_06_experimental_baseline.npy',\n",
      " 'group_04_part_07_experimental_baseline.npy',\n",
      " 'group_04_part_08_experimental_baseline.npy',\n",
      " 'group_04_part_09_experimental_baseline.npy',\n",
      " 'group_04_part_10_experimental_baseline.npy',\n",
      " 'group_04_part_11_experimental_baseline.npy',\n",
      " 'group_04_part_12_experimental_baseline.npy',\n",
      " 'group_04_part_13_experimental_baseline.npy',\n",
      " 'group_04_part_14_experimental_baseline.npy',\n",
      " 'group_04_part_15_experimental_baseline.npy']\n",
      "the number of baseline experimental files is:  15 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "group = 'group_04/' # update this to reflect the name of your group with 2 digits or SX for S1, S2, S3\n",
    "\n",
    "# path_base + group\n",
    "path_data = os.path.join(path_base,group)\n",
    "files = os.listdir(path_data)\n",
    "control_files = list()\n",
    "experimental_files = list()\n",
    "control_files_baseline = list()\n",
    "experimental_files_baseline = list()\n",
    "\n",
    "\n",
    "for f in files:\n",
    "\t# check the files that end with specific extention \n",
    "    # if a given file would need to be excluded, this is how to do it\n",
    "    #if f.rfind(\"part_10\") > -1:\n",
    "    #    continue\n",
    "    if f.endswith(\"control.npy\"):\n",
    "        control_files.append(f)\n",
    "    elif f.endswith(\"experimental.npy\"):\n",
    "        experimental_files.append(f)\n",
    "    elif f.endswith(\"control_baseline.npy\"):\n",
    "        control_files_baseline.append(f)\n",
    "    elif f.endswith(\"experimental_baseline.npy\"):\n",
    "        experimental_files_baseline.append(f)\n",
    "            \n",
    "\n",
    "# check that the length of your files list matches the provided datafiles, and contains only .npy datafiles\n",
    "\n",
    "## EVOKED files\n",
    "control_files.sort()\n",
    "pprint(control_files)\n",
    "print(\"the number of control files is: \", len(control_files), \"\\n\")\n",
    "experimental_files.sort()\n",
    "pprint(experimental_files)\n",
    "print(\"the number of experimental files is: \", len(experimental_files), \"\\n\")\n",
    "\n",
    "## BASELINE files\n",
    "control_files_baseline.sort()\n",
    "pprint(control_files_baseline)\n",
    "print(\"the number of baseline control files is: \", len(control_files_baseline), \"\\n\")\n",
    "experimental_files_baseline.sort()\n",
    "pprint(experimental_files_baseline)\n",
    "print(\"the number of baseline experimental files is: \", len(experimental_files_baseline), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-youth",
   "metadata": {},
   "source": [
    "## Combining data and matrix pre-allocation\n",
    "next, you will need to load these files one by one and extract the data for this participant. \n",
    "The data in the NumPy arrays are stored as Trials x Channels x Time. To aggregate across participants, you will thus need to add a 4th dimension to store the data.\n",
    "\n",
    "To be able to adequately pre-allocate the data from the different subjects, we will load one trial subject manually to have a look at the shape/dimensionality of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG = np.load(os.path.join(path_data,control_files[0]))\n",
    "              \n",
    "# control_files is a list of strings, so indexing its first element returns a string\n",
    "# in this case, we are loading the first entry of control_files, i.e. participant 1\n",
    "\n",
    "# verify that the number of trials equals 44, \n",
    "# verify that the number of channels equals 64 or 65 \n",
    "# and verify that there are 751 samples per trace\n",
    "\n",
    "print(\"Number of trials = \",...)\n",
    "print(\"Number of channels = \", ...)\n",
    "print(\"Number of timepoints = \", ...)\n",
    "\n",
    "# do the same for one of the baseline datafiles (they have a different number of samples)\n",
    "\n",
    "EEG_base = np.load(os.path.join(path_data,control_files_baseline[0]))\n",
    "\n",
    "print(\"Number of trials (base) = \", ...)\n",
    "print(\"Number of channels  (base) = \", ...)\n",
    "print(\"Number of timepoints (base) = \", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-labor",
   "metadata": {},
   "source": [
    "## Q1 - setting up the data structure and loading data from all participants\n",
    "\n",
    "The EEG data is currently stored as a 3-dimensional NumPy array. But to run our time-frequency analysis, we need some more information like the sampling rate and the time axis that corresponds to the stimulus-locked analysis window. In order to set up (=pre-allocate) a matrix that will hold all traces for all participants, we need to know the sizes of the dimensions of this 4-dimensional matrix, and fill up this matrix by looping over participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 64 or 65 channels in the dataset. Only channels 1-59 (not python indexes!) are EEG channels\n",
    "# the remaining channels are EMG and EOG channels that we will ignore in this analysis\n",
    "# subset your EEG array so that only the EEG channels remain\n",
    "\n",
    "##\n",
    "## Your code here\n",
    "##\n",
    "\n",
    "# Define nTrials, nChans (=channels), nSamples, nSamples_base and nParticipants. \n",
    "nTrials = ...\n",
    "nChans = ...\n",
    "nSamples = ...\n",
    "nSamples_base = ...\n",
    "nParticipants = ...\n",
    "\n",
    "# Then, pre-allocate a matrix filled with zeros and with size nParticipants x nTrials x nChans x nSamples\n",
    "# one each for the control, experimental, control_baseline and experimental_baseline data. \n",
    "# Name them: \n",
    "# data_control \n",
    "# data_experimental\n",
    "# data_control_base\n",
    "# data_experimental_base\n",
    "\n",
    "data_control = ...\n",
    "data_experimental = ...\n",
    "data_control_base = ...\n",
    "data_experimental_base = ...\n",
    "\n",
    "\n",
    "# next, we need to loop over all participant datafiles and add them to the appropriate slice in your 4-D arrays\n",
    "# For this, you need to use specific array indexing to indicate where in comb_data_(control/experimental)\n",
    "# each participant's data needs to go. You can and should reuse the data-reading code above.\n",
    "\n",
    "# CAREFUL! Not every participant may have the same number of (correct) trials in their dataset. \n",
    "# So for each newly loaded datafile, you need to establish the current number of trials again\n",
    "\n",
    "# loop over participants, and within each iteration of the loop, load the\n",
    "# next datafile and fill comb_data_(control/experimental) with the EEG traces (nTrials x nChans x nSamples)\n",
    "# check the shape of the matrices after filling them\n",
    "\n",
    "for iPart in range(len(control_files)):\n",
    "    ##\n",
    "    ## Your code here\n",
    "    ##\n",
    "    \n",
    "print(\"Shape of data_control:\",...)\n",
    "print(\"Shape of data_experimental:\",...)\n",
    "print(\"Shape of data_control_base:\",...)\n",
    "print(\"Shape of data_experimental_base:\",...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-fiber",
   "metadata": {},
   "source": [
    "Congratulations on completing this question of the Group Assignment!\n",
    "Please check the instructions for submission of this code in the Canvas Assignment. You may need to upload two files for certain assignments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 277.938,
   "position": {
    "height": "40px",
    "left": "669px",
    "right": "20px",
    "top": "11px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
